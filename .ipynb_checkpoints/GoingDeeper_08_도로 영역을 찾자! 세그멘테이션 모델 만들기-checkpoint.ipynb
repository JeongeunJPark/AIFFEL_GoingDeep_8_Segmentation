{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이 노드의 루브릭              \n",
    "---           \n",
    "\n",
    "1. U-NET을 통한 세그멘테이션 작업이 정상적으로 진행되었는가?             \n",
    "    : KITTI 데이터셋 구성, U-NET 모델 훈련, 결과물 시각화의 사이클이 정상 수행되어 세그멘테이션 결과 이미지를 제출하였다.       \n",
    "  \n",
    "  \n",
    "2. U-NET++ 모델이 성공적으로 구현되었는가?          \n",
    "    : U-NET++ 모델을 스스로 구현하여 학습 진행 후 세그멘테이션 결과까지 정상 진행되었다.           \n",
    "  \n",
    "  \n",
    "3. U-NET과 U-NET++ 두 모델의 성능이 정량적/정성적으로 잘 비교되었는가?                \n",
    "    : U-NET++의 세그멘테이션 결과 사진과 IoU 계산치를 U-NET과 비교하여 우월함을 확인하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차            \n",
    "---      \n",
    "\n",
    "1. 데이터셋 준비와 U-NET 모델의 구성            \n",
    "    -1. 데이터셋 준비          \n",
    "    -2. U-NET 모델 구성                \n",
    "    \n",
    "    \n",
    "2. U-NET++ 모델의 구성         \n",
    "    -1. U-NET++ 모델 논문 요약               \n",
    "    -2. U-NET++ 모델 구성          \n",
    "    -3. U-NET++ 모델 훈련               \n",
    "    \n",
    "    \n",
    "3. 훈련 성과 비교            \n",
    "    -1. U-NET의 IoU           \n",
    "    -2. U-NET++의 IoU             \n",
    "    -3. 비교 및 결과 요약                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 준비와 U-NET 모델의 구성          \n",
    "---\n",
    "\n",
    "### 1. 데이터셋 준비(KITTI 데이터셋의 세그멘테이션 데이터 로드)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![키티데이터셋](./PostingPic/8_kitti.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KITTI 데이터셋을 로드한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요한 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "\n",
    "# import *: 해당 모듈의 모든 함수들을 import\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "print('필요한 라이브러리 임포트 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다운로드한 데이터셋 위치\n",
    "imagedata_path = os.getenv('HOME')+'/AI_J/GoingDeeper/Semantic_data/'\n",
    "training_path = 'training/image_2'\n",
    "test_path = 'testing/image_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋을 준비하기 위한 Augmentation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import HorizontalFlip, RandomSizedCrop, Compose, OneOf, Resize\n",
    "\n",
    "def augmentations(is_train=True):\n",
    "    \n",
    "    if is_train:\n",
    "        return Compose([\n",
    "            #적용할 확률\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomSizedCrop(\n",
    "            min_max_height=(300,370),\n",
    "            w2h_ratio=370/1242,\n",
    "            #모델에 투입할 사이즈대로 조절하기 위해 h,w = (224, 224)\n",
    "            height=224,\n",
    "            width=224,\n",
    "            p=0.5),\n",
    "            Resize(width=224,height=224)\n",
    "        ])\n",
    "   \n",
    "    #훈련셋이 아닌 경우는 사이즈 조절만 수행함\n",
    "    return Compose([Resize(width=224,height=224)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = augmentations()\n",
    "\n",
    "#훈련 데이터셋 위치의 이미지들을 모두 가져옴\n",
    "input_images = glob(os.path.join(imagedata_path, training_path, \"/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssac23/AI_J/GoingDeeper/Semantic_data/training/image_2\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(imagedata_path, training_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KittiGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "               imagedata_path,\n",
    "               batch_size=16,\n",
    "               image_size=(224, 224, 3),\n",
    "               output_size=(224, 224),\n",
    "               is_train=True,\n",
    "               augmentation=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.imagedata_path = imagedata_path\n",
    "        self.augmentation = augmentation\n",
    "        self.image_size = image_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # load_dataset()을 통해서 kitti dataset의 directory path에서 라벨과 이미지를 확인합니다.\n",
    "        self.data = self.load_dataset()\n",
    "        \n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \n",
    "        #인풋 이미지\n",
    "        input_images = glob(os.path.join(imagedata_path, training_path, '/*.png'))\n",
    "        label_images = glob(os.path.join(imagedata_path, '/training/semantic/*.png'))\n",
    "        \n",
    "        #불러온 데이터셋을 sort함\n",
    "        input_images.sort()\n",
    "        label_images.sort()\n",
    "                           \n",
    "        assert len(input_images) == len(label_images)\n",
    "        \n",
    "        data = [_ for _ in zip(input_images, label_images)]\n",
    "        \n",
    "        #테스트셋 분리작업\n",
    "        if self.is_train:\n",
    "            return data[:-30]\n",
    "        return data[-30:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data)/self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data = self.data[\n",
    "            index * self.batch_size:(index+1)*self.batch_size\n",
    "        ]\n",
    "        \n",
    "        inputs = np.zeros([self.batch_size, *self.image_size])\n",
    "        outputs = np.zeros([self.batch_size, *self.output_size])\n",
    "        \n",
    "        for i, data in enumerate(batch_data):\n",
    "            input_image_path, output_image_path = data\n",
    "            _input = imread(input_image_path)\n",
    "            _output = imread(output_path)\n",
    "            _output = (_output==7).astype(np.uint8)*1\n",
    "            data = {\"image\": _input,\"mask\": _output,}\n",
    "            \n",
    "            augmented = augmentation(**data)\n",
    "            \n",
    "            #이미지는 augmented를 거쳐 반환\n",
    "            inputs[i]= augmented[\"image\"]/255\n",
    "            outputs[i]= augmented[\"mask\"]\n",
    "            \n",
    "            return inputs, outputs\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        #인덱스를 섞어 적용할 수 있도록\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        \n",
    "        if self.is_train == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            return self.indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = augmentations()\n",
    "test_augmentation = augmentations(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator= KittiGenerator(imagedata_path,augmentation=augmentation)\n",
    "test_generator = KittiGenerator(imagedata_path,augmentation=test_augmentation, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.U-Net 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 논문 모델 구조 파악"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![유넷](./PostingPic/8_unet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 논문에서 나온 위의 그림을 참고하여 확인해보자.            \n",
    "\n",
    "- 1. 각 층의 conv(3*3) + ReLU로 구성되어 있다. \n",
    "- 2. 다음 층으로 넘어갈 때는 maxPooling 층을 거친다.\n",
    "- 3. 각 층의 채널은 점차 증가하여, 5번째 층에서 1024의 정점을 찍는다.          \n",
    "- 4. 이후는 점차 채널의 수를 줄여가며 2채널로 이루어진 output을 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 논문의 implement 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위의 분석에 따른 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model_build(input_shape=(224, 224, 3)):\n",
    "    \n",
    "    #첫 인풋 이미지\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    #1계층 세트\n",
    "    #동일 구조를 4번 반복한다.\n",
    "    #Contracting_path\n",
    "    conv1 = Conv2D(64,3,activation='relu',padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128,3,activation='relu',padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256,3,activation='relu',padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512,3,activation='relu',padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2))(drop4)\n",
    "    \n",
    "    conv5 = Conv2D(1024,3,activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024,3,activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    \n",
    "    \n",
    "    #Expanding_path\n",
    "    #여기부터는 up_conv 연산을 거치게 된다.\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    up6 = Conv2DTranspose(512,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(drop5)\n",
    "    #이전의 층에서 수행한 결과값을 바탕으로 concatenate연산을 통해 합쳐준다.\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    #여기까지의 블록을 4차례 반복한다.\n",
    "    \n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    up7 = Conv2DTranspose(256,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    \n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    up7 = Conv2DTranspose(256,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    \n",
    "    conv7 = Conv2D(256, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    up8 = Conv2DTranspose(128,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    \n",
    "    conv8 = Conv2D(128, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    up9 = Conv2DTranspose(64,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    \n",
    "    conv9 = Conv2D(64, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs=conv10)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 224, 224, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 224, 224, 64) 36928       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 112, 112, 64) 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 112, 112, 128 73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 112, 112, 128 147584      conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 56, 56, 128)  0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 56, 56, 256)  295168      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 56, 56, 256)  590080      conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 28, 28, 256)  0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 28, 28, 512)  1180160     max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 28, 28, 512)  2359808     conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 28, 512)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 14, 14, 512)  0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 4719616     max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 1024) 9438208     conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 1024) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 28, 28, 512)  2097664     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 28, 28, 1024) 0           conv2d_41[0][0]                  \n",
      "                                                                 conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 28, 28, 512)  4719104     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 28, 28, 512)  2359808     conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 56, 56, 256)  524544      conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 56, 56, 512)  0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 56, 56, 256)  1179904     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 56, 56, 256)  590080      conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 112, 112, 128 131200      conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 112, 112, 256 0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 112, 112, 128 295040      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 112, 112, 128 147584      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 224, 224, 64) 32832       conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 224, 224, 128 0           conv2d_35[0][0]                  \n",
      "                                                                 conv2d_transpose_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 224, 224, 64) 73792       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 224, 224, 64) 36928       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 224, 224, 2)  1154        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 224, 224, 1)  3           conv2d_54[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_model = unet_model_build()\n",
    "\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파라미터의 수를 논문과 비교했을 때, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy')\n",
    "\n",
    "# #아래의 설정으로 훈련시킴\n",
    "# unet_model.fit_generator(generator=train_generator, validation_data=test_generator, \n",
    "#                     steps_per_epoch=len(train_generator),epochs=100)\n",
    "\n",
    "# unet_model_path = imagedata_path + '/model_his/seg_model_unet.h5'\n",
    "# unet_model.save(unet_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-NET++ 모델의 구성              \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![유넷++이미지](./PostingPic/8_unet++.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. U-NET++ 모델 논문 요약         \n",
    "---\n",
    "\n",
    "#### 3. Proposed Network Architecture : UNet++        \n",
    "\n",
    "- UNet++ 는 엔코더 서브 네트워크/백본 네트워크로 시작하여 디코더 서브 네트워크로 이어진다.     \n",
    "- UNet++가 UNet과 구분되는 점은\n",
    "    1. 재구성된 skip pathways(초록, 파랑 선으로 구분되어 있는 선) \n",
    "        - a. skip pathways에서 두 개의 서브 네트워크를 연결한다.\n",
    "        - b. deep supervision(빨간색 선)을 사용한다.\n",
    "\n",
    "#### 3-1. Re-Designed Skip pathways\n",
    "- 재구성된 skip pathways는 인코더와 디코더의 서브 네트워크를 연결한다.       \n",
    "- U-Net에서 인코더의 피쳐 맵은 곧바로 디코더로 연결되었으나, \n",
    "- UNet++에서는 __인코더의 피쳐 맵이 pyramid level에 따른 CNN layer와 Dense 레이어를 통과하도록__ 하였다.     \n",
    "\n",
    "\n",
    "- dense convolution block은 인코더의 피쳐 맵의 semantic level을 decoder의 것과 비슷하게 가져온다.    \n",
    "- 이는 최적화에 있어서 디코더의 피쳐 맵과 semantic 하게 비슷한 인코더의 피쳐 맵을 받아온다면, 최적화 문제를 보다 쉽게 해결할 수 있을 것이라는 가정을 바탕으로 고안되었다.      \n",
    "\n",
    "- 결국, 우리는 skip pathway를 다음과 같이 고안한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![수식](./PostingPic/8_수식.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $X^{i,j}$ 에서, $i$는 인코더에서의 down-sampling layer, $j$는 skip-pathway를 따라간 convolution layer의 dense block을 의미한다.          \n",
    "2. 피쳐 맵의 stack을 $X^{i,j}$ 라고 나타내기로 하고, 위의 수식과 같은 방법으로 산출한다.        \n",
    "3. $H(x)$는 activation function이 이어지는 convolution operation 이다.     \n",
    "4. $U(')$는 up-sampling layer를 의미하며, $[]$는 concatenation layer이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. Deep supervision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- UNet++에서 deep supervision을 제안하였다.          \n",
    "- 이에 따르면, 모델은 두 가지 모드에 따라 작동하게 된다.           \n",
    "    1. accurate mode : 모든 segmentation branch가 평균내어진 아웃풋이 반영되는 모드       \n",
    "    2. fast mode : 최종 segmentation map은 하나의 segmentation branch에서만 선택하여 반영하되, 그 선택은 스피드와 '가지치기' 가 반영된다.        \n",
    "    \n",
    "    \n",
    "- 이전에 설명한 skip pathway에 의해, UNet++은 deep supervision을 적용한 다중 semantic level에 대한 full resolution features를 산출하게 된다.     \n",
    "\n",
    "> {$X^{0, j}, j \\in {1,2,3,4}$}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 우리는 binary cross entropy와 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. U-NET++ 모델 구성           \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 커널 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unetplus_model_build(input_shape=(224, 224, 3)):\n",
    "    \n",
    "    #첫 인풋 이미지\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    #1계층 세트\n",
    "    #동일 구조를 4번 반복한다.\n",
    "    #Baseline \n",
    "    conv1 = Conv2D(64,3,activation='relu',padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128,3,activation='relu',padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256,3,activation='relu',padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512,3,activation='relu',padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512,3,activation='relu',padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2))(drop4)\n",
    "    \n",
    "    conv5 = Conv2D(1024,3,activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024,3,activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    \n",
    "    \n",
    "    #Expanding_path\n",
    "    #여기부터는 up_conv 연산을 거치게 된다.\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    up6 = Conv2DTranspose(512,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(drop5)\n",
    "    #이전의 층에서 수행한 결과값을 바탕으로 concatenate연산을 통해 합쳐준다.\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    #여기까지의 블록을 4차례 반복한다.\n",
    "    \n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    up7 = Conv2DTranspose(256,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    \n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    up7 = Conv2DTranspose(256,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    \n",
    "    conv7 = Conv2D(256, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    up8 = Conv2DTranspose(128,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    \n",
    "    conv8 = Conv2D(128, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    up9 = Conv2DTranspose(64,2,activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    \n",
    "    conv9 = Conv2D(64, 3, activation='relu',padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs=conv10)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. U-NET++ 모델 훈련            \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
